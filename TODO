Todo list for snogray



 [DONE]
 + Optimize triangle intersection calculation.

     (Accounts for a huge proportion of tracing time)


 [DONE]
 + Simple support for shadows of transparent/translucent objects

     Real support (bending of light rays) is too hard, but for a simple
     straight light ray, it should be easy and better than nothing.
     [For real support, caustics etc., use photon transport]


 + Implement better light-model

     Ashikhmin?  Cook-Torrance?


 + Use Fresnel equations to calculate reflectance/transmittance

     http://scienceworld.wolfram.com/physics/FresnelEquations.html


 + Get rid of seams at corners of cube-maps.  This is caused by the fact
   that the face textures run from edge to edge, and there is no
   interpolation at the edge of two adjoining faces.

   A simple fix is to simply add a 1-pixel border to each face image,
   and fill them with pixels from the adjacent face.  Then, the mapping
   from cube coordinates into texture coordinate can be slightly
   perturbed such that the face parameter range [-1, 1] maps into the
   texture parameter range [PIXW/2, 1 - PIXW/2], where "PIXW" is the
   width of one pixel in the texture's source image.

   Maybe to maintain the texture abstraction, a texture "adjoin" method
   can take care of filling in the pixels and tweaking the texture's own
   scaling factors so that the texture input parameters are still in the
   range [0, 1].


 + Texture support

     Add a "TextureMap" data type which maps between a surface point and
     texture coordinates.

     New class TexCoords to hold two texture coordinates?

     Add a "Pigment" data type, which contains a Color and a Texture
     pointer; most places where Color is now used in materials, should
     use Pigment instead (have constructors so that it can be
     initialized just like a color, resulting in a 0 Texture pointer).

     Pigment has a "color(...)" method, which takes an a texture-map and
     a location, and returns a color by using the texture-map to map the
     location into texture coordinates, and looking them in the texture
     (if the pigment's texture is 0 of course, return its color).

     Surface class gets a "texture_coords" method that returns texture
     coordinates for a given point on the surface.  PrimarySurface gets
     a new field to explicitly store a texture map, and uses that to
     implement texture_coords; mesh triangles use something else, e.g.,
     explicit per-vertex texture-coordinate tables with interpolation.

     Intersect constructor should look up and cache texture-coordinates
     for the intersection point.

     Anyplace where a Color has been replaced by a Pigment should now
     call `pigment.color (isec.tex_coords)' instead of just returning
     the color directly (when the pigment's texture pointers is 0, this
     will be almost as fast).

     Similar techniques are needed for looking up normals; shared
     superclass with textures?


 [DONE]
 + Abstract voxtree into a more generic "space division" data-type

     Allow experimenting with different implementations, e.g., KD-trees.
     [This might fit well with the voxtree generalization below.]


 + Make voxtree smarter

     See "voxtree-hacks-20050928-0.patch"

     Have different types of voxtree node for different situations:

       * Normal octree nodes

       * Leaf nodes (no children nodes, just objects)

       * Bounding-box-sub-nodes nodes:  instead of a simple octree,
	 children nodes can have an arbitrary bounding box -- this is
	 good for the case where the child(ren) has a dramatically
	 different scale, as degenerate long single chains of octree
	 nodes can be avoided (the "teapot in a stadium" problem)


 + Make voxtree searching directional

     Currently it will find object in random order; typically it would be
     much better to find closer objects first.

     For octree, put children node pointers in a length-8 array, where
     the 3 bits in the array index correspond to x-hi/lo, y-hi/lo,
     z-hi/lo respectively.  Then when starting the search at the
     top-level, we compute a quick "first check" index according to the
     rough direction of the ray we're searching for.  When iterating
     over sub-nodes in the octree, we can simply do:

	for (index_mask = 0; index_mask < 8; index_mask)
	  search_subnode (subnodes[ray_start_index ^ index_mask]);


 [DONE]
 + Soft shadows

     RectLight, FarLight.


 + Importance sampling

     Add method to Material class to supply a jittered set of rays
     (given a desired number of rays as input) corresponding to the
     Material's BRDF.  The output should be efficient for large number
     of rays (e.g. ~1000) so it can be re-sampled to combine it with
     another importance function, so each element in the set should just
     be something like <reflectance, direction> (the origin is implied). 


 + Make mirror reflections use light-model

     Use importance sampling.


 + Lighting from environment map

     Use importance resampling to combine the BRDF importance function
     with an importance function for the whole environment map (one
     hemisphere?).

     See "Bidirectional Importance Sampling for Direct Illumination",
     http://www.cs.ubc.ca/~dburke/downloads/EGSR05-Bidir_Importance.pdf


 + Global Illumination.

     Probably use "photon mapping", as described by Henrik Wann Jensen.
     See http://graphics.ucsd.edu/~henrik/papers/ewr7/


 + Better light management to handle huge numbers of lights.

     * Keep list of lights ordered in terms of "apparent strength";
       this varies per pixel, but is a good candidate for caching as it
       will change slowly for nearby points.

     * For a given point, stop calculating when the contribution from
       further lights would be negligible (radiance also adds an
       estimated term to represent lights which weren't actually
       calculated).

     * The cached ordered list of lights can have two categories: nearby
       lights and far-away lights (based on given point/bounding-box).
       When moving to a new point, we (1) see if any far-away lights
       have become "nearby", in which case we recalculate the whole
       list, and otherwise (2) reorder lights in the "nearby" list
       according to their current apparent strengths.

       Note that "nearby" lights are _not_ necessarily stronger than
       faraway lights, merely more likely to change in strength (the sun
       for instance, is probably always at the front of the "apparent
       strength" list, yet always in the faraway list).  For typical
       scenes, the number of nearby lights is probably much smaller than
       faraway lights.


 + Get rid of weird error handling in image code and just use exceptions


 + Get rid of "Image{Source,Sink}Params" classes and instead just pass
   user-supplied  "parameter strings" to image backends.

     The parameter strings can be appended to the "image type" command-line
     options, separated by ":", with "=" mean assign value.  So for
     instance, for jpeg, the user could specify "-Ojpeg:quality=98" (as the
     user will usually specify the image type indirectly via the output
     file extension, it could assume a "=" before the first ":" meant that
     the first element was a parameter rather than a type).


 + Use a similar scheme (same parser?) for test-image parameters.



;; arch-tag: 87fcbf10-c76f-43d6-9b09-469aba284b80
